{
  "hash": "d8bfe51f16e5c009caf90a7a7ccffe61",
  "result": {
    "engine": "knitr",
    "markdown": "---\ntitle: \"Readability Metrics\"\n---\n\n## Overview\n\nThe `calculate_readability_indices()` function calculates various readability metrics to assess text complexity and accessibility. These metrics are valuable for evaluating scientific writing quality and comparing sections of academic papers.\n\n## Main Function\n\n### calculate_readability_indices()\n\nCalculate multiple readability indices for text.\n\n**Usage**\n\n```r\ncalculate_readability_indices(\n  text,\n  detailed = FALSE\n)\n```\n\n**Arguments**\n\n- `text`: Character string containing the text to analyze\n- `detailed`: Logical. If TRUE, returns additional metrics and detailed statistics\n\n**Value**\n\nA data frame containing:\n\n**Basic metrics (always returned)**:\n- `flesch_reading_ease`: Flesch Reading Ease (0-100, higher = easier)\n- `flesch_kincaid_grade`: Flesch-Kincaid Grade Level\n- `gunning_fog`: Gunning Fog Index\n- `smog`: SMOG (Simple Measure of Gobbledygook) Index\n- `automated_readability`: Automated Readability Index (ARI)\n\n**Additional metrics (if detailed = TRUE)**:\n- Word count statistics\n- Sentence statistics\n- Syllable counts\n- Complex word percentages\n\n## Basic Usage\n\n### Single Text Analysis\n\n\n::: {.cell}\n\n```{.r .cell-code}\nlibrary(contentanalysis)\n\n# Import document\ndoc <- pdf2txt_auto(\"paper.pdf\", n_columns = 2)\n\n# Calculate readability for full text\nreadability <- calculate_readability_indices(\n  doc$Full_text,\n  detailed = FALSE\n)\n\nprint(readability)\n```\n:::\n\n\nExample output:\n```\n  flesch_reading_ease flesch_kincaid_grade gunning_fog smog automated_readability\n1              38.2                15.7        17.3  14.8                  16.2\n```\n\n### Detailed Analysis\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# Get detailed metrics\nreadability_detailed <- calculate_readability_indices(\n  doc$Full_text,\n  detailed = TRUE\n)\n\nprint(readability_detailed)\n\n# Additional metrics include:\n# - total_words\n# - total_sentences\n# - total_syllables\n# - avg_words_per_sentence\n# - avg_syllables_per_word\n# - complex_word_count\n# - complex_word_percentage\n```\n:::\n\n\n## Understanding Metrics\n\n### Flesch Reading Ease\n\n**Scale**: 0-100 (higher scores = easier to read)\n\n- **90-100**: Very Easy (5th grade)\n- **80-90**: Easy (6th grade)\n- **70-80**: Fairly Easy (7th grade)\n- **60-70**: Standard (8th-9th grade)\n- **50-60**: Fairly Difficult (10th-12th grade)\n- **30-50**: Difficult (College)\n- **0-30**: Very Difficult (College graduate)\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# Interpret Flesch Reading Ease\ninterpret_flesch <- function(score) {\n  if (score >= 90) \"Very Easy\"\n  else if (score >= 80) \"Easy\"\n  else if (score >= 70) \"Fairly Easy\"\n  else if (score >= 60) \"Standard\"\n  else if (score >= 50) \"Fairly Difficult\"\n  else if (score >= 30) \"Difficult\"\n  else \"Very Difficult\"\n}\n\nscore <- readability$flesch_reading_ease\ncat(\"Reading ease:\", score, \"-\", interpret_flesch(score), \"\\n\")\n```\n:::\n\n\n### Flesch-Kincaid Grade Level\n\nIndicates the U.S. grade level needed to understand the text.\n\n\n::: {.cell}\n\n```{.r .cell-code}\ngrade <- readability$flesch_kincaid_grade\n\ncat(\"Grade level required:\", round(grade, 1), \"\\n\")\n\nif (grade < 8) {\n  cat(\"Accessible to middle school students\\n\")\n} else if (grade < 12) {\n  cat(\"High school reading level\\n\")\n} else if (grade < 16) {\n  cat(\"College undergraduate level\\n\")\n} else {\n  cat(\"Graduate-level reading difficulty\\n\")\n}\n```\n:::\n\n\n### Other Indices\n\n**Gunning Fog Index**\n- Estimates years of formal education needed\n- Similar interpretation to Flesch-Kincaid\n\n**SMOG Index**\n- Based on complex words (3+ syllables)\n- Conservative estimate of reading grade\n\n**Automated Readability Index (ARI)**\n- Based on character counts\n- Corresponds to U.S. grade levels\n\n## Section Comparison\n\n### Compare All Sections\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# Calculate readability for each section\nsections_to_analyze <- c(\"Abstract\", \"Introduction\", \"Methods\", \n                        \"Results\", \"Discussion\")\n\nreadability_by_section <- data.frame()\n\nfor (section in sections_to_analyze) {\n  if (section %in% names(doc)) {\n    metrics <- calculate_readability_indices(doc[[section]], detailed = TRUE)\n    metrics$section <- section\n    readability_by_section <- rbind(readability_by_section, metrics)\n  }\n}\n\n# View results\nprint(readability_by_section)\n```\n:::\n\n\n### Visualization\n\n\n::: {.cell}\n\n```{.r .cell-code}\nlibrary(ggplot2)\nlibrary(tidyr)\n\n# Prepare data for plotting\nplot_data <- readability_by_section %>%\n  select(section, flesch_reading_ease, flesch_kincaid_grade, \n         gunning_fog, smog, automated_readability) %>%\n  pivot_longer(cols = -section, names_to = \"metric\", values_to = \"value\")\n\n# Create faceted plot\nggplot(plot_data, aes(x = section, y = value, fill = section)) +\n  geom_col(show.legend = FALSE) +\n  facet_wrap(~metric, scales = \"free_y\") +\n  labs(title = \"Readability Metrics by Section\",\n       x = \"Section\", y = \"Score\") +\n  theme_minimal() +\n  theme(axis.text.x = element_text(angle = 45, hjust = 1))\n\n# Compare Flesch Reading Ease across sections\nggplot(readability_by_section, \n       aes(x = reorder(section, flesch_reading_ease), \n           y = flesch_reading_ease, fill = section)) +\n  geom_col(show.legend = FALSE) +\n  coord_flip() +\n  labs(title = \"Flesch Reading Ease by Section\",\n       subtitle = \"Higher scores indicate easier readability\",\n       x = \"Section\", y = \"Flesch Reading Ease\") +\n  theme_minimal()\n```\n:::\n\n\n### Statistical Comparison\n\n\n::: {.cell}\n\n```{.r .cell-code}\nlibrary(dplyr)\n\n# Summary statistics\nsummary_stats <- readability_by_section %>%\n  summarise(\n    avg_ease = mean(flesch_reading_ease),\n    avg_grade = mean(flesch_kincaid_grade),\n    most_difficult = section[which.min(flesch_reading_ease)],\n    easiest = section[which.max(flesch_reading_ease)]\n  )\n\nprint(summary_stats)\n\n# Section rankings\nrankings <- readability_by_section %>%\n  select(section, flesch_reading_ease, flesch_kincaid_grade) %>%\n  arrange(desc(flesch_reading_ease))\n\ncat(\"\\nSections ranked by readability (easiest to hardest):\\n\")\nprint(rankings)\n```\n:::\n\n\n## Advanced Analysis\n\n### Word Complexity Analysis\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# Analyze word complexity if detailed = TRUE\ndetailed_metrics <- readability_by_section %>%\n  select(section, avg_words_per_sentence, avg_syllables_per_word, \n         complex_word_percentage)\n\nprint(detailed_metrics)\n\n# Visualize complexity components\nggplot(detailed_metrics, \n       aes(x = avg_words_per_sentence, y = complex_word_percentage, \n           color = section, size = avg_syllables_per_word)) +\n  geom_point(alpha = 0.7) +\n  labs(title = \"Text Complexity Components\",\n       x = \"Average Words per Sentence\",\n       y = \"Complex Word Percentage (%)\",\n       size = \"Avg Syllables per Word\") +\n  theme_minimal()\n```\n:::\n\n\n### Sentence Length Analysis\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# Compare sentence lengths across sections\nsentence_analysis <- readability_by_section %>%\n  select(section, total_sentences, total_words, avg_words_per_sentence) %>%\n  arrange(desc(avg_words_per_sentence))\n\nprint(sentence_analysis)\n\n# Identify verbose sections\nverbose_threshold <- mean(sentence_analysis$avg_words_per_sentence) + \n                    sd(sentence_analysis$avg_words_per_sentence)\n\nverbose_sections <- sentence_analysis %>%\n  filter(avg_words_per_sentence > verbose_threshold)\n\nif (nrow(verbose_sections) > 0) {\n  cat(\"\\nVerbose sections (long sentences):\\n\")\n  print(verbose_sections)\n}\n```\n:::\n\n\n### Time-Series Analysis\n\nTrack readability across document segments:\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# Divide document into segments\nn_segments <- 20\nfull_text <- doc$Full_text\ntext_length <- nchar(full_text)\nsegment_size <- text_length / n_segments\n\nsegment_readability <- data.frame()\n\nfor (i in 1:n_segments) {\n  start_pos <- (i - 1) * segment_size + 1\n  end_pos <- min(i * segment_size, text_length)\n  segment_text <- substr(full_text, start_pos, end_pos)\n  \n  metrics <- calculate_readability_indices(segment_text, detailed = FALSE)\n  metrics$segment <- i\n  segment_readability <- rbind(segment_readability, metrics)\n}\n\n# Plot trend\nggplot(segment_readability, aes(x = segment, y = flesch_reading_ease)) +\n  geom_line(color = \"steelblue\", size = 1) +\n  geom_point(color = \"steelblue\", size = 2) +\n  geom_smooth(method = \"loess\", se = TRUE, alpha = 0.2) +\n  labs(title = \"Readability Throughout Document\",\n       x = \"Document Segment\", y = \"Flesch Reading Ease\") +\n  theme_minimal()\n```\n:::\n\n\n## Comparative Studies\n\n### Compare Multiple Papers\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# Analyze multiple papers\npapers <- c(\"paper1.pdf\", \"paper2.pdf\", \"paper3.pdf\")\npaper_names <- c(\"Paper A\", \"Paper B\", \"Paper C\")\n\ncomparison <- data.frame()\n\nfor (i in seq_along(papers)) {\n  doc <- pdf2txt_auto(papers[i], n_columns = 2)\n  metrics <- calculate_readability_indices(doc$Full_text, detailed = TRUE)\n  metrics$paper <- paper_names[i]\n  comparison <- rbind(comparison, metrics)\n}\n\n# Compare papers\nprint(comparison)\n\n# Visualize\nggplot(comparison, aes(x = paper, y = flesch_reading_ease, fill = paper)) +\n  geom_col(show.legend = FALSE) +\n  labs(title = \"Readability Comparison Across Papers\",\n       x = \"Paper\", y = \"Flesch Reading Ease\") +\n  theme_minimal()\n```\n:::\n\n\n### Benchmarking\n\nCompare against discipline standards:\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# Define discipline benchmarks (example values)\nbenchmarks <- data.frame(\n  discipline = c(\"Medicine\", \"Computer Science\", \"Social Sciences\", \n                 \"Humanities\", \"Natural Sciences\"),\n  typical_fre = c(35, 42, 48, 52, 38),\n  typical_fkg = c(16, 14, 13, 12, 15)\n)\n\n# Compare paper to benchmarks\npaper_metrics <- calculate_readability_indices(doc$Full_text)\npaper_fre <- paper_metrics$flesch_reading_ease\npaper_fkg <- paper_metrics$flesch_kincaid_grade\n\n# Find closest discipline\nbenchmarks$fre_diff <- abs(benchmarks$typical_fre - paper_fre)\nclosest <- benchmarks[which.min(benchmarks$fre_diff), ]\n\ncat(\"Your paper's readability is closest to:\", closest$discipline, \"\\n\")\ncat(\"Your FRE:\", paper_fre, \"vs typical:\", closest$typical_fre, \"\\n\")\n```\n:::\n\n\n## Export Readability Data\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# Create export directory\ndir.create(\"readability_analysis\", showWarnings = FALSE)\n\n# 1. Section readability\nwrite.csv(readability_by_section,\n          \"readability_analysis/section_readability.csv\",\n          row.names = FALSE)\n\n# 2. Segment readability (if calculated)\nif (exists(\"segment_readability\")) {\n  write.csv(segment_readability,\n            \"readability_analysis/segment_readability.csv\",\n            row.names = FALSE)\n}\n\n# 3. Summary report\nsummary_report <- data.frame(\n  metric = c(\"Overall Flesch Reading Ease\",\n             \"Overall Grade Level\",\n             \"Most Readable Section\",\n             \"Least Readable Section\"),\n  value = c(\n    readability$flesch_reading_ease,\n    readability$flesch_kincaid_grade,\n    summary_stats$easiest,\n    summary_stats$most_difficult\n  )\n)\n\nwrite.csv(summary_report,\n          \"readability_analysis/summary_report.csv\",\n          row.names = FALSE)\n```\n:::\n\n\n## Interpretation Guidelines\n\n### Academic Writing Standards\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# Evaluate against academic standards\nevaluate_academic_readability <- function(fre, fkg) {\n  cat(\"\\n=== Readability Assessment ===\\n\\n\")\n  \n  # Flesch Reading Ease\n  cat(\"Flesch Reading Ease:\", round(fre, 1), \"\\n\")\n  if (fre < 30) {\n    cat(\"✓ Appropriate for academic/professional audience\\n\")\n  } else if (fre < 50) {\n    cat(\"✓ Standard academic difficulty\\n\")\n  } else {\n    cat(\"⚠ May be too simple for academic publication\\n\")\n  }\n  \n  # Grade Level\n  cat(\"\\nGrade Level:\", round(fkg, 1), \"\\n\")\n  if (fkg >= 14) {\n    cat(\"✓ College/graduate level appropriate\\n\")\n  } else if (fkg >= 12) {\n    cat(\"~ Upper undergraduate level\\n\")\n  } else {\n    cat(\"⚠ Below typical academic standard\\n\")\n  }\n  \n  # Recommendations\n  cat(\"\\nRecommendations:\\n\")\n  if (fre > 50) {\n    cat(\"- Consider using more technical vocabulary\\n\")\n    cat(\"- Increase sentence complexity where appropriate\\n\")\n  }\n  if (fkg < 12) {\n    cat(\"- Add more complex sentence structures\\n\")\n    cat(\"- Incorporate domain-specific terminology\\n\")\n  }\n  if (fre < 25 || fkg > 18) {\n    cat(\"- Consider breaking up very long sentences\\n\")\n    cat(\"- Ensure clarity is not sacrificed for complexity\\n\")\n  }\n}\n\n# Apply to your document\nmetrics <- calculate_readability_indices(doc$Full_text)\nevaluate_academic_readability(metrics$flesch_reading_ease, \n                              metrics$flesch_kincaid_grade)\n```\n:::\n\n\n## Tips and Best Practices\n\n::: {.callout-tip}\n## Interpreting Results\n\n- **Context matters**: Technical papers naturally score lower\n- **Section differences**: Methods often harder than Discussion\n- **Audience consideration**: Adjust expectations by field\n- **Balance**: Clarity vs. necessary complexity\n:::\n\n::: {.callout-tip}\n## Improving Readability\n\nTo improve scores while maintaining rigor:\n\n1. Break long sentences into shorter ones\n2. Use active voice when possible\n3. Define technical terms clearly\n4. Vary sentence length and structure\n5. Use transitional phrases effectively\n:::\n\n::: {.callout-note}\n## Academic Standards\n\nTypical academic papers:\n\n- **FRE**: 30-50 (Difficult to Fairly Difficult)\n- **FK Grade**: 13-16 (College to Graduate level)\n- **Gunning Fog**: 14-18\n\nLower scores aren't always better for academic writing!\n:::\n\n## See Also\n\n- [Text Analysis](text-analysis.qmd): Word frequency and n-grams\n- [Content Analysis](content-analysis.qmd): Comprehensive analysis\n- [Tutorial](../tutorial.qmd): Complete workflow examples",
    "supporting": [],
    "filters": [
      "rmarkdown/pagebreak.lua"
    ],
    "includes": {},
    "engineDependencies": {},
    "preserve": {},
    "postProcess": true
  }
}